{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout \n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_column_name = ['1', '2', '3', '4', '5','6','7','8','9','10','11','12','13']\n",
    "predicted_class_name = ['class']\n",
    "X_train = df[feature_column_name].values\n",
    "y_train = df[predicted_class_name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_column_name_test = ['1', '2', '3', '4', '5','6','7','8','9','10','11','12','13']\n",
    "predicted_class_name_test = ['class']\n",
    "X_test = df_test[feature_column_name_test].values\n",
    "y_test = df_test[predicted_class_name_test].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = np_utils.to_categorical(y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Keras Sequential Model To train The Training data (31200 x 13 matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout \n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fully_connected_model = Sequential()\n",
    "fully_connected_model.add(Dense(300, input_dim = 13, kernel_initializer='normal', activation='relu',name = 'main_input'))\n",
    "fully_connected_model.add(Dense(200, kernel_initializer='normal'))\n",
    "fully_connected_model.add(Dense(100, kernel_initializer='normal'))\n",
    "fully_connected_model.add(Dense(50, kernel_initializer='normal'))\n",
    "fully_connected_model.add(Dense(20, kernel_initializer='normal', activation='softmax'))\n",
    "fully_connected_model.compile(loss='categorical_crossentropy',optimizer ='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1s - loss: 1.8472 - acc: 0.3640\n",
      "Epoch 2/10\n",
      "0s - loss: 1.8395 - acc: 0.3633\n",
      "Epoch 3/10\n",
      "0s - loss: 1.8417 - acc: 0.3648\n",
      "Epoch 4/10\n",
      "0s - loss: 1.8240 - acc: 0.3692\n",
      "Epoch 5/10\n",
      "0s - loss: 1.8334 - acc: 0.3695\n",
      "Epoch 6/10\n",
      "0s - loss: 1.8161 - acc: 0.3693\n",
      "Epoch 7/10\n",
      "0s - loss: 1.8222 - acc: 0.3684\n",
      "Epoch 8/10\n",
      "0s - loss: 1.8091 - acc: 0.3737\n",
      "Epoch 9/10\n",
      "0s - loss: 1.8061 - acc: 0.3772\n",
      "Epoch 10/10\n",
      "0s - loss: 1.8027 - acc: 0.3758\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25588b1b940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_connected_model.fit(X_train, y_train, epochs =10, batch_size=200,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Training Data(31200 x 13 matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.5769230769%\n"
     ]
    }
   ],
   "source": [
    "losses, accuracy = fully_connected_model.evaluate(X_train, y_train, verbose=2)\n",
    "print(str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Test Data (31200 x 13 matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.0641025641%\n"
     ]
    }
   ],
   "source": [
    "losses, accuracy = fully_connected_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Keras Sequential Model To train The Training data (480 x 845 matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Frame Shape Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(480, 845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_flatten = []\n",
    "i=0\n",
    "for j in range(0, 480):\n",
    "    y_train_flatten.append(i)\n",
    "    if len(y_train_flatten)%24 == 0:\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(120, 845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_flatten = []\n",
    "i=0\n",
    "for j in range(0, 120):\n",
    "    y_test_flatten.append(i)\n",
    "    if len(y_test_flatten)%6 == 0:\n",
    "        i=i+1\n",
    "        \n",
    "                #y_test_flatten.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = np_utils.to_categorical(y_test_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fully_connected_model = Sequential()\n",
    "fully_connected_model.add(Dense(300, input_dim = 845, kernel_initializer='normal', activation='relu',name = 'main_input'))\n",
    "fully_connected_model.add(Dense(200, kernel_initializer='normal'))\n",
    "fully_connected_model.add(Dense(100, kernel_initializer='normal'))\n",
    "fully_connected_model.add(Dense(50, kernel_initializer='normal'))\n",
    "fully_connected_model.add(Dense(20, kernel_initializer='normal', activation='softmax'))\n",
    "fully_connected_model.compile(loss='categorical_crossentropy',optimizer ='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "0s - loss: 0.1389 - acc: 0.9792\n",
      "Epoch 2/10\n",
      "0s - loss: 0.0951 - acc: 0.9875\n",
      "Epoch 3/10\n",
      "0s - loss: 0.0677 - acc: 0.9958\n",
      "Epoch 4/10\n",
      "0s - loss: 0.0441 - acc: 1.0000\n",
      "Epoch 5/10\n",
      "0s - loss: 0.0325 - acc: 1.0000\n",
      "Epoch 6/10\n",
      "0s - loss: 0.0229 - acc: 1.0000\n",
      "Epoch 7/10\n",
      "0s - loss: 0.0175 - acc: 1.0000\n",
      "Epoch 8/10\n",
      "0s - loss: 0.0140 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "0s - loss: 0.0111 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "0s - loss: 0.0092 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25588b1bef0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fully_connected_model.fit(X_train, y_train, epochs =10, batch_size=200,verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Training Data( 480 x 845 matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "losses, accuracy = fully_connected_model.evaluate(X_train, y_train, verbose=2)\n",
    "print(str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Test Data (480 x 845 matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0%\n"
     ]
    }
   ],
   "source": [
    "losses, accuracy = fully_connected_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Keras Convolutional Neural Network Model To train The Training data (31200 x 13 matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Frame Shape Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31200, 13)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(31200,13)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(480, 65, 13 , 1).astype('float32')\n",
    "X_test = X_test.reshape(120, 65, 13 , 1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 20)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D,  MaxPooling1D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kernel_size = (3, 3)\n",
    "pool_size = (63, 11)\n",
    "num_classes = 20\n",
    "\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(693, kernel_size, padding='valid', input_shape=(65, 13, 1)))\n",
    "cnn_model.add(Activation('relu'))\n",
    "cnn_model.add(MaxPooling2D(pool_size=pool_size))\n",
    "cnn_model.add(Dropout(0.2))\n",
    "cnn_model.add(Flatten())\n",
    "# cnn_model.add(Dense(300))\n",
    "# cnn_model.add(Dense(200))\n",
    "# cnn_model.add(Dense(100))\n",
    "#cnn_model.add(Dense(50))\n",
    "#-------------------------------------------------#\n",
    "# kernel_size = (3, 3)\n",
    "# pool_size = (61, 9)\n",
    "# cnn_model.add(Conv2D(549, kernel_size, padding='valid', input_shape=(63, 11, 1)))\n",
    "# cnn_model.add(Activation('relu'))\n",
    "# cnn_model.add(MaxPooling2D(pool_size=pool_size))\n",
    "# cnn_model.add(Dropout(0.2))\n",
    "# cnn_model.add(Flatten())\n",
    "#-------------------------------------------------#\n",
    "cnn_model.add(Activation('relu'))\n",
    "cnn_model.add(Dense(num_classes))\n",
    "cnn_model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "0s - loss: 2.6043 - acc: 0.2646\n",
      "Epoch 2/10\n",
      "0s - loss: 2.6279 - acc: 0.2104\n",
      "Epoch 3/10\n",
      "0s - loss: 2.5256 - acc: 0.2500\n",
      "Epoch 4/10\n",
      "0s - loss: 2.3910 - acc: 0.3229\n",
      "Epoch 5/10\n",
      "0s - loss: 2.3645 - acc: 0.3250\n",
      "Epoch 6/10\n",
      "0s - loss: 2.4263 - acc: 0.2896\n",
      "Epoch 7/10\n",
      "0s - loss: 2.5273 - acc: 0.2437\n",
      "Epoch 8/10\n",
      "0s - loss: 2.3006 - acc: 0.3375\n",
      "Epoch 9/10\n",
      "0s - loss: 2.3847 - acc: 0.3021\n",
      "Epoch 10/10\n",
      "0s - loss: 2.2865 - acc: 0.3458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x255883ca390>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(X_train, y_train, epochs=10, batch_size=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Training Data( 31200 x 13 matrix )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.7916666667%\n"
     ]
    }
   ],
   "source": [
    "losses, accuracy = cnn_model.evaluate(X_train, y_train, verbose=2)\n",
    "print(str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.8333333333%\n"
     ]
    }
   ],
   "source": [
    "losses, accuracy = cnn_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Apply Keras 1D Convolutional Neural Network Model To train The Training data (31200 x 13 matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df = pd.read_csv('training_data.csv')\n",
    "feature_column_name = ['1', '2', '3', '4', '5','6','7','8','9','10','11','12','13']\n",
    "predicted_class_name = ['class']\n",
    "X_train = df[feature_column_name].values\n",
    "y_train = df[predicted_class_name].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_flatten = []\n",
    "i=0\n",
    "for j in range(0, 480):\n",
    "    y_train_flatten.append(i)\n",
    "    if len(y_train_flatten)%24 == 0:\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train_flatten) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31200, 13)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(1, 480, 845)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.reshape(1,480,20) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 480, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_data.csv')\n",
    "feature_column_name_test = ['1', '2', '3', '4', '5','6','7','8','9','10','11','12','13']\n",
    "predicted_class_name_test = ['class']\n",
    "X_test = df_test[feature_column_name_test].values\n",
    "#y_test = df_test[predicted_class_name_test].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test_flatten = []\n",
    "i=0\n",
    "for j in range(0, 120):\n",
    "    y_test_flatten.append(i)\n",
    "    if len(y_test_flatten)%6 == 0:\n",
    "        i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = np_utils.to_categorical(y_test_flatten) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = X_test.reshape(1, 120, 845)\n",
    "y_test = y_test.reshape(1, 120, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 120, 20)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_model_1d = Sequential()\n",
    "cnn_model_1d.add(Conv1D(200, input_shape=(480, 845), kernel_size=1, filters=5))\n",
    "#cnn_model_1d.add(Flatten())\n",
    "cnn_model_1d.add(Dense(num_classes))\n",
    "cnn_model_1d.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 480, 845)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_1d.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s - loss: 13.9329 - acc: 0.0438\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s - loss: 13.3422 - acc: 0.0479\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s - loss: 12.5777 - acc: 0.0563\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s - loss: 11.7584 - acc: 0.0688\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s - loss: 11.0493 - acc: 0.0854\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s - loss: 10.6564 - acc: 0.0938\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s - loss: 10.3300 - acc: 0.0979\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s - loss: 10.0416 - acc: 0.0958\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s - loss: 9.7167 - acc: 0.1021\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s - loss: 9.4190 - acc: 0.1125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2566ea842e8>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model_1d.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.2916722298%\n"
     ]
    }
   ],
   "source": [
    "losses, accuracy = cnn_model_1d.evaluate(X_train, y_train, verbose=2)\n",
    "print(str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected conv1d_3_input to have shape (None, 480, 845) but got array with shape (1, 120, 845)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-11064d52c59e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcnn_model_1d\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'%'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight)\u001b[0m\n\u001b[0;32m    894\u001b[0m                                    \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m                                    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 896\u001b[1;33m                                    sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[0;32m   1644\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1645\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1646\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1647\u001b[0m         \u001b[1;31m# Prepare inputs, delegate logic to `_test_loop`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1648\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1376\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1378\u001b[1;33m                                     exception_prefix='input')\n\u001b[0m\u001b[0;32m   1379\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[0;32m   1380\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    142\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m                             str(array.shape))\n\u001b[0m\u001b[0;32m    145\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected conv1d_3_input to have shape (None, 480, 845) but got array with shape (1, 120, 845)"
     ]
    }
   ],
   "source": [
    "losses, accuracy = cnn_model_1d.evaluate(X_test, y_test, verbose=2)\n",
    "print(str(accuracy*100)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 0s - loss: 0.3518\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s - loss: 0.3359\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s - loss: 0.3024\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s - loss: 0.2012\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s - loss: 0.1300\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s - loss: 0.0664\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s - loss: 0.0348\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s - loss: 0.0163\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s - loss: 0.0079\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s - loss: 0.0036\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2178c0a9198>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test=np.random.random_sample((1,100,5))\n",
    "x_test\n",
    "y_test=np.random.randint(2,size=1) # target for 1 sample\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(input_shape=(100,5),kernel_size=2,filters=1)) # 100 timesteps of 5 features each\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "model.fit(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
